import torch
import tqdm
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import pandas as pd

def evaluate(model, data_loader, criterion, device):
    
    model.eval()    
    accuracy, num_corrects, num_samples = 0, 0, 0
    loss, val_loss = 0, 0
    model.zero_grad(set_to_none=True)

    for imgs, labels in data_loader:
            
        imgs = imgs.to(device, dtype=torch.float)
        labels = labels.type(torch.LongTensor)

        labels = labels.to(device)
        with torch.set_grad_enabled(False):

            outputs = model(imgs)
            _, yhats = torch.max(outputs, 1)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            num_corrects += torch.sum(yhats == labels.data)
            num_samples += yhats.size(0)
    accuracy = float(100 * num_corrects / num_samples)
    val_loss = float(val_loss)
    # print(f'Epoch: {epoch} | Accuracy: {accuracy:.2f}%')
    
    return accuracy, val_loss



def predictions(model, data_loader, device):
    
    model.eval()    
    model.zero_grad(set_to_none=True)
    y_pred, y_true = [], []
    for imgs, labels in data_loader:
            
        imgs = imgs.to(device, dtype=torch.float)
        labels = labels.type(torch.LongTensor)
        labels = labels.to(device)
        
        with torch.set_grad_enabled(False):

            outputs = model(imgs)
            _, yhats = torch.max(outputs, 1)
            y_pred.extend(yhats.detach().tolist())
            y_true.extend(labels.detach().tolist())
    
    return y_true, y_pred


def calculate_confusion_matrix(y_true, y_pred):
    """
    A function that returns the confusion matrix returned by 
    confusion_matrix(y_true, y_pred) from scikit-learn
    
    ...
    
    Args:
        y_true: list
            A list of integers contains the true labels of the corresponding images
        Y_pred : list
            A list of integers contains the labels predicted by the BrainTumorClassifier
    ...
    
    """
    
    return confusion_matrix(y_true, y_pred)


def plot_cf_matrix(cf_matrix, classes):
    """
    A function used to plot the confusion matrix as a heatmap table
    
    ...
    
    Args:
        cf_matrix: ndarray
            The confusion matrix generated by 
            confusion_matrix(y_true, y_pred) from scikit-learn
        classes : list
            A list of strings containing the class labels
    
    ...
    
    """
    
    cf_matrix_dataFrame = pd.DataFrame(cf_matrix, index = classes, columns = classes)
    fig, ax = plt.subplots()    
    plt.title("Confusion Matrix")
    sns.heatmap(cf_matrix_dataFrame, annot=True, fmt='.0f')
    plt.yticks(rotation=0) 
    plt.xticks(rotation=0) 
    plt.show()
    
 
def get_classification_report(y_true, y_pred, labels=None, target_names=None):
    """
    A function that returns the classification report generted from scikit-learn
    using the true and predicted labels
    
    ...
    
    Args:
        y_true: list
            A list of integers contains the true labels of the corresponding images
        Y_pred : list
            A list of integers contains the labels predicted by the BrainTumorClassifier
        labels: list
            An optional list of label indices to include in the report
        target_names:
            An optional list of string containing the names of classes matching the labels
    ...
    
    """
    return classification_report(y_true=y_true,
                                 y_pred=y_pred,
                                 labels=labels,
                                 target_names=target_names)  
     
    
def plot_per_class_accuracy(cf_matrix, classes):
    """
    A function used to plot the classification accuracy for each class
    
    ...
    
    Args:
        cf_matrix: ndarray
            The confusion matrix generated by 
            confusion_matrix(y_true, y_pred) from scikit-learn
        classes : list
            A list of strings containing the class labels
    
    ...
    
    """
    accs = cf_matrix.diagonal() / cf_matrix.sum(1)    
    fig, ax = plt.subplots(figsize=(10, 6))
    bars = ax.bar(classes, accs)
    ax.bar_label(bars)
    plt.title('Class Accuracy')
    plt.ylabel("Accuracy %")
    plt.xlabel("Class Label")
    plt.xticks(classes)
    plt.show()
    
         
    